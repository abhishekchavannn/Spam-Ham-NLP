{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "28f432bd-2609-45d7-8c62-05bd8b9c5544",
   "metadata": {},
   "source": [
    "# Spam-Ham\n",
    "Dataset obtained from: https://archive.ics.uci.edu/ml/datasets/sms+spam+collection\n",
    "\n",
    "It contains over 5000 SMS labeled messages that have been collected for mobile phone spam research.\n",
    "This is a text classification for the mentioned dataset, using Natural Language Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "94a20fee-72e5-4a72-90e7-9041123a6d99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python Version: 3.9.5 (tags/v3.9.5:0a7dcbd, May  3 2021, 17:27:52) [MSC v.1928 64 bit (AMD64)]\n",
      "Sci-Kit-learn Version: 0.24.2\n",
      "NLTK Version: 3.6.2\n",
      "Pandas Version: 1.2.4\n",
      "NumPy Version: 1.19.5\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import sklearn\n",
    "import nltk\n",
    "import pandas\n",
    "import numpy\n",
    "\n",
    "print('Python Version: {}'.format(sys.version))\n",
    "print('Sci-Kit-learn Version: {}'.format(sklearn.__version__))\n",
    "print('NLTK Version: {}'.format(nltk.__version__))\n",
    "print('Pandas Version: {}'.format(pandas.__version__))\n",
    "print('NumPy Version: {}'.format(numpy.__version__))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5b37ed5f-a7fa-464c-8316-c3488700784a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# load the dataset of the SMS messages\n",
    "df = pd.read_table('SMSSpamCollection', header = None, encoding = 'utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9e891602-6b7a-4eb0-aad4-bdf6eb6d2c9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5572 entries, 0 to 5571\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   0       5572 non-null   object\n",
      " 1   1       5572 non-null   object\n",
      "dtypes: object(2)\n",
      "memory usage: 87.2+ KB\n",
      "None\n",
      "      0                                                  1\n",
      "0   ham  Go until jurong point, crazy.. Available only ...\n",
      "1   ham                      Ok lar... Joking wif u oni...\n",
      "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
      "3   ham  U dun say so early hor... U c already then say...\n",
      "4   ham  Nah I don't think he goes to usf, he lives aro...\n"
     ]
    }
   ],
   "source": [
    "print(df.info())\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "410a1b00-351f-4e0b-b397-e6006fc69797",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ham     4825\n",
      "spam     747\n",
      "Name: 0, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "classes = df[0]\n",
    "print(classes.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8d3b593d-3016-417d-a84c-248591113235",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 1 0 0 1 0 0 1 1]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "encoder = LabelEncoder()\n",
    "Y = encoder.fit_transform(classes)\n",
    "print(Y[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8c607490-12d0-440b-a6db-4167ed62e989",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    Go until jurong point, crazy.. Available only ...\n",
      "1                        Ok lar... Joking wif u oni...\n",
      "2    Free entry in 2 a wkly comp to win FA Cup fina...\n",
      "3    U dun say so early hor... U c already then say...\n",
      "4    Nah I don't think he goes to usf, he lives aro...\n",
      "5    FreeMsg Hey there darling it's been 3 week's n...\n",
      "6    Even my brother is not like to speak with me. ...\n",
      "7    As per your request 'Melle Melle (Oru Minnamin...\n",
      "8    WINNER!! As a valued network customer you have...\n",
      "9    Had your mobile 11 months or more? U R entitle...\n",
      "Name: 1, dtype: object\n"
     ]
    }
   ],
   "source": [
    "text_messages = df[1]\n",
    "print(text_messages[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3f43a14a-73c0-4afe-8656-cffaa51364fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-15-95a32f5ec9b4>:2: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  processed = text_messages.str.replace(r'^.+@[^\\.].*\\.[a-z]{2,}$','emailaddress')\n",
      "<ipython-input-15-95a32f5ec9b4>:5: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  processed = processed.str.replace(r'^http\\://[a-zA-Z0-9\\-\\.]+\\.[a-zA-Z]{2,3}(/\\S*)?$', 'webaddress')\n",
      "<ipython-input-15-95a32f5ec9b4>:8: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  processed = processed.str.replace(r'£|\\$', 'moneysymb')\n",
      "<ipython-input-15-95a32f5ec9b4>:11: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  processed = processed.str.replace(r'^\\(?[\\d]{3}\\)?[\\s-]?[\\d]{3}[\\s-]?[\\d]{4}$', 'phonenumbr')\n",
      "<ipython-input-15-95a32f5ec9b4>:14: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  processed = processed.str.replace(r'\\d+(\\.\\d+)?', 'numbr')\n",
      "<ipython-input-15-95a32f5ec9b4>:17: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  processed = processed.str.replace(r'[^\\w\\d\\s]', ' ')\n",
      "<ipython-input-15-95a32f5ec9b4>:20: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  processed = processed.str.replace(r'\\s+', ' ')\n",
      "<ipython-input-15-95a32f5ec9b4>:23: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  processed = processed.str.replace(r'^\\s+|\\s+?$', '')\n"
     ]
    }
   ],
   "source": [
    "# Replacing email addresses with 'emailaddress'\n",
    "processed = text_messages.str.replace(r'^.+@[^\\.].*\\.[a-z]{2,}$','emailaddress')\n",
    "\n",
    "# Replacing URLs with 'webaddress'\n",
    "processed = processed.str.replace(r'^http\\://[a-zA-Z0-9\\-\\.]+\\.[a-zA-Z]{2,3}(/\\S*)?$', 'webaddress')\n",
    "\n",
    "# Replace money symbols with 'moneysymb'\n",
    "processed = processed.str.replace(r'£|\\$', 'moneysymb')\n",
    "\n",
    "# Replace 10 digit phone numbers  with 'phonenumber'\n",
    "processed = processed.str.replace(r'^\\(?[\\d]{3}\\)?[\\s-]?[\\d]{3}[\\s-]?[\\d]{4}$', 'phonenumbr')\n",
    "\n",
    "# Replace numbers with 'numbr'\n",
    "processed = processed.str.replace(r'\\d+(\\.\\d+)?', 'numbr')\n",
    "\n",
    "# Remove punctuation\n",
    "processed = processed.str.replace(r'[^\\w\\d\\s]', ' ')\n",
    "\n",
    "# Replace whitespace between terms with a single space\n",
    "processed = processed.str.replace(r'\\s+', ' ')\n",
    "\n",
    "# Remove leading and trailing whitespace\n",
    "processed = processed.str.replace(r'^\\s+|\\s+?$', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "93446f74-f12d-48ea-8583-dd943a2e8398",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0       go until jurong point crazy available only in ...\n",
      "1                                 ok lar joking wif u oni\n",
      "2       free entry in numbr a wkly comp to win fa cup ...\n",
      "3             u dun say so early hor u c already then say\n",
      "4       nah i don t think he goes to usf he lives arou...\n",
      "                              ...                        \n",
      "5567    this is the numbrnd time we have tried numbr c...\n",
      "5568                  will ü b going to esplanade fr home\n",
      "5569    pity was in mood for that so any other suggest...\n",
      "5570    the guy did some bitching but i acted like i d...\n",
      "5571                            rofl its true to its name\n",
      "Name: 1, Length: 5572, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Changing everything to lower case\n",
    "\n",
    "processed = processed.str.lower()\n",
    "print(processed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5b42a677-a2f7-48f1-92b2-c9b5083ab46b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "\n",
    "# Removing the stop words from text messages\n",
    "\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "processed = processed.apply(lambda x: ' '.join(term for term in x.split() if term not in \n",
    "                                               stop_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "91f1449a-05aa-4131-9b30-3dd0a527a2af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing the word stems (ex: -ing, -ed etc)\n",
    "\n",
    "ps = nltk.PorterStemmer()\n",
    "\n",
    "processed = processed.apply(lambda x: ' '.join(ps.stem(term) for term in x.split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ed7aeed7-6922-41c9-b823-49bb55ca43d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generating the features\n",
    "\n",
    "from nltk.tokenize import word_tokenize\n",
    "all_words = []\n",
    "\n",
    "for message in processed:\n",
    "    words = word_tokenize(message)\n",
    "    for w in words:\n",
    "        all_words.append(w)\n",
    "        \n",
    "all_words = nltk.FreqDist(all_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5dd8f115-c485-4129-b0f2-23a3712c6d38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of words: 6579\n",
      "Most common words: [('numbr', 2648), ('u', 1207), ('call', 674), ('go', 456), ('get', 451), ('ur', 391), ('gt', 318), ('lt', 316), ('come', 304), ('moneysymbnumbr', 303), ('ok', 293), ('free', 284), ('day', 276), ('know', 275), ('love', 266)]\n"
     ]
    }
   ],
   "source": [
    "# Printing the 15 most common words\n",
    "\n",
    "print('Number of words: {}'.format(len(all_words)))\n",
    "print('Most common words: {}'.format(all_words.most_common(15)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "111b4811-7e06-4b89-9aec-0253efbfb533",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_features = list(all_words.keys())[:1500] # using 1500 most common words as features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b67c2617-1629-4571-80f7-532ba3194b92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "go\n",
      "jurong\n",
      "point\n",
      "crazi\n",
      "avail\n",
      "bugi\n",
      "n\n",
      "great\n",
      "world\n",
      "la\n",
      "e\n",
      "buffet\n",
      "cine\n",
      "got\n",
      "amor\n",
      "wat\n"
     ]
    }
   ],
   "source": [
    "# find_features function will determine which of the 1500 word features are contained in the review\n",
    "\n",
    "def find_features(message):\n",
    "    words = word_tokenize(message)\n",
    "    features = {}\n",
    "    for word in word_features:\n",
    "        features[word] = (word in words)\n",
    "\n",
    "    return features\n",
    "\n",
    "# Lets see an example!\n",
    "features = find_features(processed[0])\n",
    "for key, value in features.items():\n",
    "    if value == True:\n",
    "        print (key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a29c9b69-be8a-4f60-bf87-142af9cf5131",
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = list(zip(processed, Y))\n",
    "seed = 1\n",
    "np.random.seed = seed\n",
    "np.random.shuffle(messages)\n",
    "\n",
    "featuresets = [(find_features(text), label) for (text, label) in messages]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "1e4f1e03-5874-4363-8cca-a12acd8ce24d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import model_selection\n",
    "\n",
    "training, testing = model_selection.train_test_split(featuresets, test_size = 0.25, random_state = seed )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "cadf4f3f-2348-4750-91e5-4fdcf22ab26d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4179\n",
      "1393\n"
     ]
    }
   ],
   "source": [
    "print(len(training))\n",
    "print(len(testing))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f7f52157-bc5e-4fb8-8b76-421fcb37d6c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVC Accuracy: 98.85139985642498\n"
     ]
    }
   ],
   "source": [
    "from nltk.classify.scikitlearn import SklearnClassifier\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "model = SklearnClassifier(SVC(kernel = 'linear'))\n",
    "model.train(training)\n",
    "accuracy = nltk.classify.accuracy(model, testing)*100\n",
    "\n",
    "print(\"SVC Accuracy: {}\".format(accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "69abd73e-0e51-422c-9d18-5969af237621",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K Nearest Neighbors Accuracy: 94.75951184493898\n",
      "Decision Tree Accuracy: 97.34386216798278\n",
      "Random Forest Accuracy: 98.7078248384781\n",
      "Logistic Regression Accuracy: 98.85139985642498\n",
      "SGD Classifier Accuracy: 98.63603732950466\n",
      "Naive Bayes Accuracy: 98.85139985642498\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression, SGDClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix\n",
    "\n",
    "names = [\"K Nearest Neighbors\",\n",
    "        \"Decision Tree\",\n",
    "        \"Random Forest\",\n",
    "        \"Logistic Regression\",\n",
    "        \"SGD Classifier\",\n",
    "        \"Naive Bayes\",\n",
    "        \"SVM Linear\"]\n",
    "\n",
    "classifiers = [\n",
    "    KNeighborsClassifier(),\n",
    "    DecisionTreeClassifier(),\n",
    "    RandomForestClassifier(),\n",
    "    SGDClassifier(max_iter = 100),\n",
    "    MultinomialNB(),\n",
    "    SVC(kernel = 'linear')\n",
    "]\n",
    "\n",
    "models = zip(names, classifiers)\n",
    "\n",
    "for name, model in models:\n",
    "    nltk_model = SklearnClassifier(model)\n",
    "    nltk_model.train(training)\n",
    "    accuracy = nltk.classify.accuracy(nltk_model, testing)*100\n",
    "    print(\"{} Accuracy: {}\".format(name, accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "cba9deed-2ac3-4287-b413-51b7fac887ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Voting Classifier accuracy: 98.85139985642498\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "names = [\"K Nearest Neighbors\", \"Decision Tree\", \"Random Forest\", \"Logistic Regression\", \"SGD Classifier\",\n",
    "         \"Naive Bayes\", \"SVM Linear\"]\n",
    "\n",
    "classifiers = [\n",
    "    KNeighborsClassifier(),\n",
    "    DecisionTreeClassifier(),\n",
    "    RandomForestClassifier(),\n",
    "    LogisticRegression(),\n",
    "    SGDClassifier(max_iter = 100),\n",
    "    MultinomialNB(),\n",
    "    SVC(kernel = 'linear')\n",
    "]\n",
    "\n",
    "models = list(zip(names, classifiers))\n",
    "\n",
    "nltk_ensemble = SklearnClassifier(VotingClassifier(estimators = models, voting = 'hard', n_jobs = -1))\n",
    "nltk_ensemble.train(training)\n",
    "accuracy = nltk.classify.accuracy(nltk_model, testing)*100\n",
    "print(\"Voting Classifier accuracy: {}\".format(accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "d8eb3066-cc84-4740-b032-bd2af7c78551",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making class label predictions for testing set\n",
    "txt_features, labels = list(zip(*testing))\n",
    "prediction = nltk_ensemble.classify_many(txt_features)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "d5ab3b15-5fe1-46a6-9338-39626cf8cecd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      0.99      1215\n",
      "           1       0.99      0.93      0.96       178\n",
      "\n",
      "    accuracy                           0.99      1393\n",
      "   macro avg       0.99      0.97      0.98      1393\n",
      "weighted avg       0.99      0.99      0.99      1393\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th colspan=\"2\" halign=\"left\">predicted</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>ham</th>\n",
       "      <th>spam</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">actual</th>\n",
       "      <th>ham</th>\n",
       "      <td>1213</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ham</th>\n",
       "      <td>12</td>\n",
       "      <td>166</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           predicted     \n",
       "                 ham spam\n",
       "actual ham      1213    2\n",
       "       ham        12  166"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(classification_report(labels, prediction))\n",
    "\n",
    "\n",
    "pd.DataFrame(\n",
    "    confusion_matrix(labels, prediction),\n",
    "    index =[['actual','actual'],['ham','ham']],\n",
    "    columns = [['predicted','predicted'], ['ham','spam']])\n",
    "      "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
